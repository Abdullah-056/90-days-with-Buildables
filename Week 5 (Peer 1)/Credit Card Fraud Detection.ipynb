{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6492730,"sourceType":"datasetVersion","datasetId":3752264}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:49.123635Z","iopub.execute_input":"2025-09-20T11:47:49.124578Z","iopub.status.idle":"2025-09-20T11:47:49.135322Z","shell.execute_reply.started":"2025-09-20T11:47:49.124534Z","shell.execute_reply":"2025-09-20T11:47:49.134398Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/credit-card-fraud-detection-dataset-2023/creditcard_2023.csv\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv(\"/kaggle/input/credit-card-fraud-detection-dataset-2023/creditcard_2023.csv\", usecols=lambda col: col != 'id')\nprint(data.shape)\npd.set_option('display.max_column', None)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:49.143274Z","iopub.execute_input":"2025-09-20T11:47:49.143765Z","iopub.status.idle":"2025-09-20T11:47:54.249742Z","shell.execute_reply.started":"2025-09-20T11:47:49.143736Z","shell.execute_reply":"2025-09-20T11:47:54.248500Z"}},"outputs":[{"name":"stdout","text":"(568630, 30)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"         V1        V2        V3        V4        V5        V6        V7  \\\n0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0 -0.130006  0.727159  0.637735 -0.987020  0.293438 -0.941386  0.549020   \n1 -0.133118  0.347452  0.529808  0.140107  1.564246  0.574074  0.627719   \n2 -0.095576 -0.261297  0.690708 -0.272985  0.659201  0.805173  0.616874   \n3 -0.065130 -0.205698  0.575231 -0.752581  0.737483  0.592994  0.559535   \n4 -0.212660  1.049921  0.968046 -1.203171  1.029577  1.439310  0.241454   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.804879  0.215598  0.512307  0.333644  0.124270  0.091202 -0.110552   \n1  0.706121  0.789188  0.403810  0.201799 -0.340687 -0.233984 -0.194936   \n2  3.069025 -0.577514  0.886526  0.239442 -2.366079  0.361652 -0.005020   \n3 -0.697664 -0.030669  0.242629  2.178616 -1.345060 -0.378223 -0.146927   \n4  0.153008  0.224538  0.366466  0.291782  0.445317  0.247237 -0.106984   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.217606 -0.134794  0.165959  0.126280 -0.434824 -0.081230 -0.151045   \n1 -0.605761  0.079469 -0.577395  0.190090  0.296503 -0.248052 -0.064512   \n2  0.702906  0.945045 -1.154666 -0.605564 -0.312895 -0.300258 -0.244718   \n3 -0.038212 -0.214048 -1.893131  1.003963 -0.515950 -0.165316  0.048424   \n4  0.729727 -0.161666  0.312561 -0.414116  1.071126  0.023712  0.419117   \n\n     Amount  Class  \n0  17982.10      0  \n1   6531.37      0  \n2   2513.54      0  \n3   5384.44      0  \n4  14278.97      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.260648</td>\n      <td>-0.469648</td>\n      <td>2.496266</td>\n      <td>-0.083724</td>\n      <td>0.129681</td>\n      <td>0.732898</td>\n      <td>0.519014</td>\n      <td>-0.130006</td>\n      <td>0.727159</td>\n      <td>0.637735</td>\n      <td>-0.987020</td>\n      <td>0.293438</td>\n      <td>-0.941386</td>\n      <td>0.549020</td>\n      <td>1.804879</td>\n      <td>0.215598</td>\n      <td>0.512307</td>\n      <td>0.333644</td>\n      <td>0.124270</td>\n      <td>0.091202</td>\n      <td>-0.110552</td>\n      <td>0.217606</td>\n      <td>-0.134794</td>\n      <td>0.165959</td>\n      <td>0.126280</td>\n      <td>-0.434824</td>\n      <td>-0.081230</td>\n      <td>-0.151045</td>\n      <td>17982.10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.985100</td>\n      <td>-0.356045</td>\n      <td>0.558056</td>\n      <td>-0.429654</td>\n      <td>0.277140</td>\n      <td>0.428605</td>\n      <td>0.406466</td>\n      <td>-0.133118</td>\n      <td>0.347452</td>\n      <td>0.529808</td>\n      <td>0.140107</td>\n      <td>1.564246</td>\n      <td>0.574074</td>\n      <td>0.627719</td>\n      <td>0.706121</td>\n      <td>0.789188</td>\n      <td>0.403810</td>\n      <td>0.201799</td>\n      <td>-0.340687</td>\n      <td>-0.233984</td>\n      <td>-0.194936</td>\n      <td>-0.605761</td>\n      <td>0.079469</td>\n      <td>-0.577395</td>\n      <td>0.190090</td>\n      <td>0.296503</td>\n      <td>-0.248052</td>\n      <td>-0.064512</td>\n      <td>6531.37</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.260272</td>\n      <td>-0.949385</td>\n      <td>1.728538</td>\n      <td>-0.457986</td>\n      <td>0.074062</td>\n      <td>1.419481</td>\n      <td>0.743511</td>\n      <td>-0.095576</td>\n      <td>-0.261297</td>\n      <td>0.690708</td>\n      <td>-0.272985</td>\n      <td>0.659201</td>\n      <td>0.805173</td>\n      <td>0.616874</td>\n      <td>3.069025</td>\n      <td>-0.577514</td>\n      <td>0.886526</td>\n      <td>0.239442</td>\n      <td>-2.366079</td>\n      <td>0.361652</td>\n      <td>-0.005020</td>\n      <td>0.702906</td>\n      <td>0.945045</td>\n      <td>-1.154666</td>\n      <td>-0.605564</td>\n      <td>-0.312895</td>\n      <td>-0.300258</td>\n      <td>-0.244718</td>\n      <td>2513.54</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.152152</td>\n      <td>-0.508959</td>\n      <td>1.746840</td>\n      <td>-1.090178</td>\n      <td>0.249486</td>\n      <td>1.143312</td>\n      <td>0.518269</td>\n      <td>-0.065130</td>\n      <td>-0.205698</td>\n      <td>0.575231</td>\n      <td>-0.752581</td>\n      <td>0.737483</td>\n      <td>0.592994</td>\n      <td>0.559535</td>\n      <td>-0.697664</td>\n      <td>-0.030669</td>\n      <td>0.242629</td>\n      <td>2.178616</td>\n      <td>-1.345060</td>\n      <td>-0.378223</td>\n      <td>-0.146927</td>\n      <td>-0.038212</td>\n      <td>-0.214048</td>\n      <td>-1.893131</td>\n      <td>1.003963</td>\n      <td>-0.515950</td>\n      <td>-0.165316</td>\n      <td>0.048424</td>\n      <td>5384.44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.206820</td>\n      <td>-0.165280</td>\n      <td>1.527053</td>\n      <td>-0.448293</td>\n      <td>0.106125</td>\n      <td>0.530549</td>\n      <td>0.658849</td>\n      <td>-0.212660</td>\n      <td>1.049921</td>\n      <td>0.968046</td>\n      <td>-1.203171</td>\n      <td>1.029577</td>\n      <td>1.439310</td>\n      <td>0.241454</td>\n      <td>0.153008</td>\n      <td>0.224538</td>\n      <td>0.366466</td>\n      <td>0.291782</td>\n      <td>0.445317</td>\n      <td>0.247237</td>\n      <td>-0.106984</td>\n      <td>0.729727</td>\n      <td>-0.161666</td>\n      <td>0.312561</td>\n      <td>-0.414116</td>\n      <td>1.071126</td>\n      <td>0.023712</td>\n      <td>0.419117</td>\n      <td>14278.97</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Taking only small portion of data \nprint(\"Actual Datasize : \",data.shape)\ndata = data.sample(50000)\nprint(\"Reduced Datasize : \",data.shape)\n\ndata2 = data.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.251498Z","iopub.execute_input":"2025-09-20T11:47:54.252045Z","iopub.status.idle":"2025-09-20T11:47:54.293741Z","shell.execute_reply.started":"2025-09-20T11:47:54.252017Z","shell.execute_reply":"2025-09-20T11:47:54.292835Z"}},"outputs":[{"name":"stdout","text":"Actual Datasize :  (568630, 30)\nReduced Datasize :  (50000, 30)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"data.isnull().sum()\n# Data has no null values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.294603Z","iopub.execute_input":"2025-09-20T11:47:54.294871Z","iopub.status.idle":"2025-09-20T11:47:54.308550Z","shell.execute_reply.started":"2025-09-20T11:47:54.294850Z","shell.execute_reply":"2025-09-20T11:47:54.307361Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"V1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"cat_cols = data.select_dtypes(include=['object']).columns\nprint(\"Categorical Columns ; \", cat_cols)\n\nint_cols = [col for col in data.columns if col not in cat_cols]\nprint(\"Non-categorical Columns ; \", int_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.310463Z","iopub.execute_input":"2025-09-20T11:47:54.310753Z","iopub.status.idle":"2025-09-20T11:47:54.330545Z","shell.execute_reply.started":"2025-09-20T11:47:54.310731Z","shell.execute_reply":"2025-09-20T11:47:54.329450Z"}},"outputs":[{"name":"stdout","text":"Categorical Columns ;  Index([], dtype='object')\nNon-categorical Columns ;  ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"Column names are not present because They are created in a result of PCA. ","metadata":{}},{"cell_type":"code","source":"data['Class'].value_counts()\n# It displays that values are balanced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.331580Z","iopub.execute_input":"2025-09-20T11:47:54.331942Z","iopub.status.idle":"2025-09-20T11:47:54.351435Z","shell.execute_reply.started":"2025-09-20T11:47:54.331911Z","shell.execute_reply":"2025-09-20T11:47:54.350299Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Class\n0    25050\n1    24950\nName: count, dtype: int64"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"As our data is now transformed and is ready for Data Visulaization and ML Model Creation. ","metadata":{}},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"def iqr_limits(data, col):\n    q1 = data[col].quantile(0.25)\n    q3 = data[col].quantile(0.75)\n    \n    iqr = q3 - q1\n    lower = q1 - (1.5 * iqr)\n    upper = q3 + (1.5 * iqr)\n    return upper, lower","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.352453Z","iopub.execute_input":"2025-09-20T11:47:54.352809Z","iopub.status.idle":"2025-09-20T11:47:54.371682Z","shell.execute_reply.started":"2025-09-20T11:47:54.352780Z","shell.execute_reply":"2025-09-20T11:47:54.370481Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"skew, not_skew = [], []\n\nX = data.drop('Class', axis=1)\nY = data['Class']\n\nfor col in X.columns:\n    sk = data[col].skew()\n    print(f\"Column [{col}] is {sk:.2f}\", end = '\\t')\n    if sk > - 0.5 and sk < 0.5:\n        print(f\"{col} is Symmetric\")\n        not_skew.append(col)\n    elif sk > -1 and sk < -1:\n        print(f\"{col} is Moderately Skewed\")\n        skew.append(col)\n    else:\n        print(f\"{col} is Skewed\")\n        skew.append(col)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.372694Z","iopub.execute_input":"2025-09-20T11:47:54.372957Z","iopub.status.idle":"2025-09-20T11:47:54.416013Z","shell.execute_reply.started":"2025-09-20T11:47:54.372936Z","shell.execute_reply":"2025-09-20T11:47:54.414850Z"}},"outputs":[{"name":"stdout","text":"Column [V1] is -0.08\tV1 is Symmetric\nColumn [V2] is -1.31\tV2 is Skewed\nColumn [V3] is 0.02\tV3 is Symmetric\nColumn [V4] is -0.03\tV4 is Symmetric\nColumn [V5] is 2.48\tV5 is Skewed\nColumn [V6] is -0.33\tV6 is Symmetric\nColumn [V7] is -0.32\tV7 is Symmetric\nColumn [V8] is 0.15\tV8 is Symmetric\nColumn [V9] is 0.15\tV9 is Symmetric\nColumn [V10] is 0.60\tV10 is Skewed\nColumn [V11] is -0.02\tV11 is Symmetric\nColumn [V12] is 0.18\tV12 is Symmetric\nColumn [V13] is 0.03\tV13 is Symmetric\nColumn [V14] is 0.34\tV14 is Symmetric\nColumn [V15] is -0.01\tV15 is Symmetric\nColumn [V16] is 0.08\tV16 is Symmetric\nColumn [V17] is 0.39\tV17 is Symmetric\nColumn [V18] is 0.14\tV18 is Symmetric\nColumn [V19] is -0.01\tV19 is Symmetric\nColumn [V20] is -0.69\tV20 is Skewed\nColumn [V21] is -0.37\tV21 is Symmetric\nColumn [V22] is 0.40\tV22 is Symmetric\nColumn [V23] is -0.16\tV23 is Symmetric\nColumn [V24] is 0.03\tV24 is Symmetric\nColumn [V25] is 0.02\tV25 is Symmetric\nColumn [V26] is -0.03\tV26 is Symmetric\nColumn [V27] is 0.23\tV27 is Symmetric\nColumn [V28] is 1.21\tV28 is Skewed\nColumn [Amount] is -0.01\tAmount is Symmetric\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def iqr_method(data, cols):\n    results = {}\n    for col in cols:\n        q1 = data[col].quantile(0.25)\n        q3 = data[col].quantile(0.75)\n    \n        iqr = q3 - q1\n        lower = q1 - (1.5 * iqr)\n        upper = q3 + (1.5 * iqr)\n        outlier = data[(data[col] < lower) | (data[col] > upper)]\n        results[col] = len(outlier)\n        print(f\"The {col} : {len(outlier)} outliers or {(len(outlier)/len(data))* 100} % outliers\")\n        data[col] = np.where(data[col] > upper, upper, np.where(data[col] < lower, lower, data[col]))\n        print(\"After Imputation: \")\n        outlier = data[(data[col] < lower) | (data[col] > upper)]\n        print(f\"The {col} : {len(outlier)} outliers or {(len(outlier)/len(data)) * 100} % outliers\")\n        print(\"--------------------------------------------------------------------\")\n    # return outlier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.417049Z","iopub.execute_input":"2025-09-20T11:47:54.417339Z","iopub.status.idle":"2025-09-20T11:47:54.425891Z","shell.execute_reply.started":"2025-09-20T11:47:54.417290Z","shell.execute_reply":"2025-09-20T11:47:54.424700Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"print(f\"Columns that are not skew are {len(not_skew)}: \")\nprint(not_skew)\nprint(\"-----------------------------------\")\nprint(f\"Columns that are skewed {len(skew)}: \")\nprint(skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.427189Z","iopub.execute_input":"2025-09-20T11:47:54.427579Z","iopub.status.idle":"2025-09-20T11:47:54.445712Z","shell.execute_reply.started":"2025-09-20T11:47:54.427554Z","shell.execute_reply":"2025-09-20T11:47:54.444718Z"}},"outputs":[{"name":"stdout","text":"Columns that are not skew are 24: \n['V1', 'V3', 'V4', 'V6', 'V7', 'V8', 'V9', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'Amount']\n-----------------------------------\nColumns that are skewed 5: \n['V2', 'V5', 'V10', 'V20', 'V28']\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"## Skewed Data","metadata":{}},{"cell_type":"code","source":"# Before outlier Removal\nplt.figure(figsize=(14, 6))\nk=1\nfor col in skew:\n    plt.subplot(2, 4, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.448902Z","iopub.execute_input":"2025-09-20T11:47:54.449676Z","iopub.status.idle":"2025-09-20T11:47:54.823669Z","shell.execute_reply.started":"2025-09-20T11:47:54.449648Z","shell.execute_reply":"2025-09-20T11:47:54.822636Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# skew_out = \niqr_method(data, skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.825061Z","iopub.execute_input":"2025-09-20T11:47:54.825334Z","iopub.status.idle":"2025-09-20T11:47:54.871795Z","shell.execute_reply.started":"2025-09-20T11:47:54.825314Z","shell.execute_reply":"2025-09-20T11:47:54.870821Z"}},"outputs":[{"name":"stdout","text":"The V2 : 3732 outliers or 7.4639999999999995 % outliers\nAfter Imputation: \nThe V2 : 0 outliers or 0.0 % outliers\n--------------------------------------------------------------------\nThe V5 : 6313 outliers or 12.626000000000001 % outliers\nAfter Imputation: \nThe V5 : 0 outliers or 0.0 % outliers\n--------------------------------------------------------------------\nThe V10 : 972 outliers or 1.944 % outliers\nAfter Imputation: \nThe V10 : 0 outliers or 0.0 % outliers\n--------------------------------------------------------------------\nThe V20 : 5808 outliers or 11.616 % outliers\nAfter Imputation: \nThe V20 : 0 outliers or 0.0 % outliers\n--------------------------------------------------------------------\nThe V28 : 6243 outliers or 12.486 % outliers\nAfter Imputation: \nThe V28 : 0 outliers or 0.0 % outliers\n--------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# After Outlier Removal\nplt.figure(figsize=(14, 6))\nk=1\nfor col in skew:\n    plt.subplot(3, 3, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.872732Z","iopub.execute_input":"2025-09-20T11:47:54.872983Z","iopub.status.idle":"2025-09-20T11:47:55.206823Z","shell.execute_reply.started":"2025-09-20T11:47:54.872963Z","shell.execute_reply":"2025-09-20T11:47:55.205892Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(18, 8))\nk=1\nfor col in skew:\n    upper, lower = iqr_limits(data, col)\n    plt.subplot(4, 2, k)\n    sns.kdeplot(data[col], fill = True, label=f\"Imputed {col}\")\n    sns.kdeplot(data2[col], fill = True, label=col)\n    plt.axvline(x=lower, linestyle='--', color='r', label='Lower Limit')\n    plt.axvline(x=upper, linestyle='--', color='g', label='Upper Limit')\n    plt.xlabel(col)\n    plt.grid()\n\n    # plt.xlim([(data2[col].min()) , data2[col].max()])\n    plt.legend()\n    k +=1\n\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:55.207777Z","iopub.execute_input":"2025-09-20T11:47:55.208028Z","iopub.status.idle":"2025-09-20T11:47:58.397308Z","shell.execute_reply.started":"2025-09-20T11:47:55.207999Z","shell.execute_reply":"2025-09-20T11:47:58.396357Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"Using Box Plot to Visualize the Outliers. ","metadata":{}},{"cell_type":"markdown","source":"## Non-skewed Data","metadata":{}},{"cell_type":"code","source":"# Before outlier Removal\nplt.figure(figsize=(26, 18))\nk=1\nfor col in not_skew:\n    plt.subplot(7, 4, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:58.398242Z","iopub.execute_input":"2025-09-20T11:47:58.398523Z","iopub.status.idle":"2025-09-20T11:48:00.333932Z","shell.execute_reply.started":"2025-09-20T11:47:58.398502Z","shell.execute_reply":"2025-09-20T11:48:00.332933Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def detect_using_zscore(data, col, threshold=3):\n    \n    mean = data[col].mean()\n    std = data[col].std()\n        \n    if std == 0:\n        print(f\"Column '{col}' has zero standard deviation. No outliers possible.\")\n        return 0,0\n\n    lower_limit = mean - threshold * std\n    upper_limit = mean + threshold * std\n    return lower_limit, upper_limit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:00.335178Z","iopub.execute_input":"2025-09-20T11:48:00.335463Z","iopub.status.idle":"2025-09-20T11:48:00.341362Z","shell.execute_reply.started":"2025-09-20T11:48:00.335443Z","shell.execute_reply":"2025-09-20T11:48:00.340035Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(48, 30))\nk=1\nfor col in not_skew:\n    upper, lower = iqr_limits(data, col)\n    plt.subplot(9, 3, k)\n    # sns.kdeplot(data[col], fill = True, label=f\"Imputed {col}\")\n    sns.kdeplot(data[col], fill = True, label=col)\n    plt.axvline(x=lower, linestyle='--', color='r', label='Lower Limit')\n    plt.axvline(x=upper, linestyle='--', color='g', label='Upper Limit')\n    plt.xlabel(col)\n    plt.grid()\n\n    # plt.xlim([(data2[col].min()) , data2[col].max()])\n    plt.legend()\n    k +=1\n\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:00.342576Z","iopub.execute_input":"2025-09-20T11:48:00.342860Z","iopub.status.idle":"2025-09-20T11:48:09.825899Z","shell.execute_reply.started":"2025-09-20T11:48:00.342838Z","shell.execute_reply":"2025-09-20T11:48:09.824915Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef detect_and_impute_outliers(data, columns, threshold=3):\n    if isinstance(columns, set):\n        columns = list(columns)\n    \n    for col in columns:\n        if col not in data.columns:\n            print(f\"Column '{col}' not found in data. Skipping.\")\n            continue\n        \n        mean = data[col].mean()\n        std = data[col].std()\n        \n        if std == 0:\n            print(f\"Column '{col}' has zero standard deviation. No outliers possible.\")\n            continue\n        \n        lower_limit = mean - threshold * std\n        upper_limit = mean + threshold * std\n        \n        # Count initial outliers\n        num_outliers = ((data[col] < lower_limit) | (data[col] > upper_limit)).sum()\n        \n        print(f\"For column '{col}':\")\n        # print(f\"  Mean: {mean:.4f}\")\n        # print(f\"  Std: {std:.4f}\")\n        print(f\"  Lower limit (outlier if below): {lower_limit:.4f}\")\n        print(f\"  Upper limit (outlier if above): {upper_limit:.4f}\")\n        print(f\"  Number of outliers before imputation: {num_outliers}\")\n        \n        # Impute by clipping\n        data[col] = np.where(data[col] > upper_limit, upper_limit, np.where(data[col] < lower_limit, lower_limit, data[col]))\n        \n        # Recount outliers to confirm\n        num_outliers_after = ((data[col] < lower_limit) | (data[col] > upper_limit)).sum()\n        print(f\"  Number of outliers after imputation: {num_outliers_after}\")\n        print(\"---\"*15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.826946Z","iopub.execute_input":"2025-09-20T11:48:09.827445Z","iopub.status.idle":"2025-09-20T11:48:09.838420Z","shell.execute_reply.started":"2025-09-20T11:48:09.827416Z","shell.execute_reply":"2025-09-20T11:48:09.837303Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"detect_and_impute_outliers(data, not_skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.839407Z","iopub.execute_input":"2025-09-20T11:48:09.840254Z","iopub.status.idle":"2025-09-20T11:48:09.920285Z","shell.execute_reply.started":"2025-09-20T11:48:09.840153Z","shell.execute_reply":"2025-09-20T11:48:09.919229Z"}},"outputs":[{"name":"stdout","text":"For column 'V1':\n  Lower limit (outlier if below): -2.9988\n  Upper limit (outlier if above): 3.0102\n  Number of outliers before imputation: 0\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V3':\n  Lower limit (outlier if below): -2.9922\n  Upper limit (outlier if above): 2.9867\n  Number of outliers before imputation: 129\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V4':\n  Lower limit (outlier if below): -2.9890\n  Upper limit (outlier if above): 2.9947\n  Number of outliers before imputation: 112\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V6':\n  Lower limit (outlier if below): -3.0069\n  Upper limit (outlier if above): 3.0187\n  Number of outliers before imputation: 520\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V7':\n  Lower limit (outlier if below): -2.8242\n  Upper limit (outlier if above): 2.8194\n  Number of outliers before imputation: 707\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V8':\n  Lower limit (outlier if below): -2.9848\n  Upper limit (outlier if above): 2.9740\n  Number of outliers before imputation: 1506\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V9':\n  Lower limit (outlier if below): -3.0045\n  Upper limit (outlier if above): 3.0088\n  Number of outliers before imputation: 401\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V11':\n  Lower limit (outlier if below): -2.9977\n  Upper limit (outlier if above): 2.9996\n  Number of outliers before imputation: 34\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V12':\n  Lower limit (outlier if below): -3.0155\n  Upper limit (outlier if above): 3.0191\n  Number of outliers before imputation: 85\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V13':\n  Lower limit (outlier if below): -2.9930\n  Upper limit (outlier if above): 3.0020\n  Number of outliers before imputation: 171\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V14':\n  Lower limit (outlier if below): -3.0124\n  Upper limit (outlier if above): 3.0143\n  Number of outliers before imputation: 132\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V15':\n  Lower limit (outlier if below): -3.0028\n  Upper limit (outlier if above): 3.0046\n  Number of outliers before imputation: 205\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V16':\n  Lower limit (outlier if below): -2.9903\n  Upper limit (outlier if above): 2.9873\n  Number of outliers before imputation: 210\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V17':\n  Lower limit (outlier if below): -2.9984\n  Upper limit (outlier if above): 2.9982\n  Number of outliers before imputation: 543\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V18':\n  Lower limit (outlier if below): -3.0026\n  Upper limit (outlier if above): 3.0055\n  Number of outliers before imputation: 380\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V19':\n  Lower limit (outlier if below): -3.0004\n  Upper limit (outlier if above): 2.9968\n  Number of outliers before imputation: 310\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V21':\n  Lower limit (outlier if below): -3.0438\n  Upper limit (outlier if above): 3.0357\n  Number of outliers before imputation: 912\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V22':\n  Lower limit (outlier if below): -3.0067\n  Upper limit (outlier if above): 3.0106\n  Number of outliers before imputation: 866\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V23':\n  Lower limit (outlier if below): -2.9658\n  Upper limit (outlier if above): 2.9769\n  Number of outliers before imputation: 848\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V24':\n  Lower limit (outlier if below): -2.9947\n  Upper limit (outlier if above): 2.9981\n  Number of outliers before imputation: 46\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V25':\n  Lower limit (outlier if below): -2.9689\n  Upper limit (outlier if above): 2.9691\n  Number of outliers before imputation: 659\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V26':\n  Lower limit (outlier if below): -3.0034\n  Upper limit (outlier if above): 3.0033\n  Number of outliers before imputation: 245\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'V27':\n  Lower limit (outlier if below): -2.9790\n  Upper limit (outlier if above): 2.9602\n  Number of outliers before imputation: 1322\n  Number of outliers after imputation: 0\n---------------------------------------------\nFor column 'Amount':\n  Lower limit (outlier if below): -8652.5428\n  Upper limit (outlier if above): 32837.5895\n  Number of outliers before imputation: 0\n  Number of outliers after imputation: 0\n---------------------------------------------\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"# Data Visulization","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nv = []\nfor i in range(1, 29):\n    add = \"V\" + str(i)\n    v.append(add)\n    \n# from matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 12))\nj = 1\nfor val in v:\n    plt.subplot(4, 7, j)\n    sns.kdeplot(data[val], fill = True, label=val)\n    plt.xlabel(val)\n    plt.grid()\n    plt.legend()\n    j = j+1\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.921301Z","iopub.execute_input":"2025-09-20T11:48:09.921854Z","iopub.status.idle":"2025-09-20T11:48:19.261126Z","shell.execute_reply.started":"2025-09-20T11:48:09.921819Z","shell.execute_reply":"2025-09-20T11:48:19.259797Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"sns.kdeplot(data=data, x='Amount', fill=True)\nplt.grid()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:19.262330Z","iopub.execute_input":"2025-09-20T11:48:19.262641Z","iopub.status.idle":"2025-09-20T11:48:20.260456Z","shell.execute_reply.started":"2025-09-20T11:48:19.262619Z","shell.execute_reply":"2025-09-20T11:48:20.259247Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"binn = [0, 1000, 2500, 5000, 10000, 15000, 20000, 25000]\nlabels = ['Under 1k', '1k to 2.5k', '2.5k to 5k', '5k to 10k', '10k to 15k', '15k to 20k', '20k to 25k']\ndata['Amount_in_bins'] = pd.cut(data['Amount'], labels = labels, bins=binn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:20.261457Z","iopub.execute_input":"2025-09-20T11:48:20.261717Z","iopub.status.idle":"2025-09-20T11:48:20.271455Z","shell.execute_reply.started":"2025-09-20T11:48:20.261697Z","shell.execute_reply":"2025-09-20T11:48:20.270215Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"sns.histplot(data['Amount_in_bins'])\nplt.xticks(rotation=45)\nplt.xlabel(\"Amount in Categories\")\nplt.ylabel(\"No. of Transactions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:20.272682Z","iopub.execute_input":"2025-09-20T11:48:20.273059Z","iopub.status.idle":"2025-09-20T11:48:21.116755Z","shell.execute_reply.started":"2025-09-20T11:48:20.273026Z","shell.execute_reply":"2025-09-20T11:48:21.115877Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"Text(1737.928571428571, 0.5, 'No. of Transactions')"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\ncolor = ['purple', 'orange', 'purple', 'orange']\n(data.groupby('Amount_in_bins')['Class'].value_counts()).plot(kind='bar', color=color)\nplt.xticks(rotation=90)\nplt.grid()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.118013Z","iopub.execute_input":"2025-09-20T11:48:21.118336Z","iopub.status.idle":"2025-09-20T11:48:21.265564Z","shell.execute_reply.started":"2025-09-20T11:48:21.118314Z","shell.execute_reply":"2025-09-20T11:48:21.264486Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"data.groupby('Amount_in_bins')['Class'].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.267081Z","iopub.execute_input":"2025-09-20T11:48:21.267475Z","iopub.status.idle":"2025-09-20T11:48:21.285706Z","shell.execute_reply.started":"2025-09-20T11:48:21.267443Z","shell.execute_reply":"2025-09-20T11:48:21.284509Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"Amount_in_bins  Class\nUnder 1k        0        1020\n                1         970\n1k to 2.5k      0        1519\n                1        1484\n2.5k to 5k      0        2637\n                1        2574\n5k to 10k       1        5178\n                0        5119\n10k to 15k      0        5278\n                1        5247\n15k to 20k      0        5332\n                1        5242\n20k to 25k      1        4255\n                0        4145\nName: count, dtype: int64"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"i=0\nfraud_by_bin = data.groupby('Amount_in_bins')['Class'].value_counts()\nfor val in labels:\n    non_fraud = fraud_by_bin[i]/(fraud_by_bin[i] + fraud_by_bin[i+1])\n    fraud = fraud_by_bin[i+1]/(fraud_by_bin[i] + fraud_by_bin[i+1])\n    print(f\"Chances of Fraud when transaction of {val} is made is : {fraud*100:.2f}%\")\n    print(f\"Chances of not_Fraud when transaction of {val} is made is : {non_fraud*100:.2f}%\")\n    i=i+2\n    print(\"----\"*20)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.287217Z","iopub.execute_input":"2025-09-20T11:48:21.287557Z","iopub.status.idle":"2025-09-20T11:48:21.305698Z","shell.execute_reply.started":"2025-09-20T11:48:21.287533Z","shell.execute_reply":"2025-09-20T11:48:21.304302Z"}},"outputs":[{"name":"stdout","text":"Chances of Fraud when transaction of Under 1k is made is : 48.74%\nChances of not_Fraud when transaction of Under 1k is made is : 51.26%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 1k to 2.5k is made is : 49.42%\nChances of not_Fraud when transaction of 1k to 2.5k is made is : 50.58%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 2.5k to 5k is made is : 49.40%\nChances of not_Fraud when transaction of 2.5k to 5k is made is : 50.60%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 5k to 10k is made is : 49.71%\nChances of not_Fraud when transaction of 5k to 10k is made is : 50.29%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 10k to 15k is made is : 49.85%\nChances of not_Fraud when transaction of 10k to 15k is made is : 50.15%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 15k to 20k is made is : 49.57%\nChances of not_Fraud when transaction of 15k to 20k is made is : 50.43%\n--------------------------------------------------------------------------------\nChances of Fraud when transaction of 20k to 25k is made is : 49.35%\nChances of not_Fraud when transaction of 20k to 25k is made is : 50.65%\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"all_num = [col for col in data.columns if col != 'Amount_in_bins']\nplt.figure(figsize=(20,12), dpi =500)\nsns.heatmap(data[all_num].corr(), annot=True,fmt=\".2f\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.306792Z","iopub.execute_input":"2025-09-20T11:48:21.307835Z","iopub.status.idle":"2025-09-20T11:48:23.433981Z","shell.execute_reply.started":"2025-09-20T11:48:21.307809Z","shell.execute_reply":"2025-09-20T11:48:23.433160Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<Axes: >"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"data['Class'].value_counts().plot(kind='pie', labels=[ 'Not Fraud', 'Fraud'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:23.435117Z","iopub.execute_input":"2025-09-20T11:48:23.435441Z","iopub.status.idle":"2025-09-20T11:48:24.061427Z","shell.execute_reply.started":"2025-09-20T11:48:23.435418Z","shell.execute_reply":"2025-09-20T11:48:24.060469Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<Axes: ylabel='count'>"},"metadata":{}}],"execution_count":62},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nX = data2.drop('Class', axis=1)\nY = data2['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\nX_test = st.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.065328Z","iopub.execute_input":"2025-09-20T11:48:24.065632Z","iopub.status.idle":"2025-09-20T11:48:24.113160Z","shell.execute_reply.started":"2025-09-20T11:48:24.065611Z","shell.execute_reply":"2025-09-20T11:48:24.112141Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# Section 3: Machine Learning Model Training\n\n# Import necessary libraries for modeling\nimport pandas as pd\nimport os\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n\n# Initialize a dictionary to hold our models\nmodels = {\n    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42),\n    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),  # eval_metric for binary classification\n    'LightGBM': LGBMClassifier(random_state=42),\n    'CatBoost': CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 to suppress training output\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.114036Z","iopub.execute_input":"2025-09-20T11:48:24.114300Z","iopub.status.idle":"2025-09-20T11:48:24.121554Z","shell.execute_reply.started":"2025-09-20T11:48:24.114279Z","shell.execute_reply":"2025-09-20T11:48:24.120437Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Train each model and save its predictions and probabilities\nfor name, model in models.items():\n    print(f'\\n--- Training {name} ---')\n    \n    model.fit(X_train, y_train)\n    \n    # Make predictions on the test set\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n    \n    # Clean model name for file saving\n    model_name_cleaned = name.replace(' ', '_').lower()\n    \n    # Save predictions and probabilities to CSV files in current working directory\n    os.makedirs(\"y_Predictions\", exist_ok=True)\n    os.makedirs(\"y_Probabilities\", exist_ok=True)\n    pd.DataFrame(y_pred).to_csv(f'y_Predictions/y_pred_{model_name_cleaned}.csv', index=False)\n    pd.DataFrame(y_proba).to_csv(f'y_Probabilities/y_proba_{model_name_cleaned}.csv', index=False)\n    \n    print(f'{name} training complete. Predictions and probabilities saved.')\n\nprint('\\nAll selected models have been trained and their predictions/probabilities saved for evaluation.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.122643Z","iopub.execute_input":"2025-09-20T11:48:24.122923Z","iopub.status.idle":"2025-09-20T11:49:06.267562Z","shell.execute_reply.started":"2025-09-20T11:48:24.122901Z","shell.execute_reply":"2025-09-20T11:49:06.266374Z"}},"outputs":[{"name":"stdout","text":"\n--- Training Logistic Regression ---\nLogistic Regression training complete. Predictions and probabilities saved.\n\n--- Training Random Forest ---\nRandom Forest training complete. Predictions and probabilities saved.\n\n--- Training XGBoost ---\nXGBoost training complete. Predictions and probabilities saved.\n\n--- Training LightGBM ---\n[LightGBM] [Info] Number of positive: 20006, number of negative: 19994\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007302 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7395\n[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 29\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500150 -> initscore=0.000600\n[LightGBM] [Info] Start training from score 0.000600\nLightGBM training complete. Predictions and probabilities saved.\n\n--- Training CatBoost ---\nCatBoost training complete. Predictions and probabilities saved.\n\nAll selected models have been trained and their predictions/probabilities saved for evaluation.\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries for evaluation\nimport pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    ConfusionMatrixDisplay, roc_curve\n)\n\nimport matplotlib\nmatplotlib.use(\"Agg\")  # Use a non-interactive backend\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Define the list of models for which we have predictions\nmodels_to_evaluate = [\n    \"logistic_regression\",\n    \"random_forest\",\n    \"xgboost\",\n    \"lightgbm\",\n    \"catboost\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:06.268577Z","iopub.execute_input":"2025-09-20T11:49:06.268859Z","iopub.status.idle":"2025-09-20T11:49:06.275724Z","shell.execute_reply.started":"2025-09-20T11:49:06.268838Z","shell.execute_reply":"2025-09-20T11:49:06.274452Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"\nresults = {}\n\nprint(\"\\n--- Evaluating Model Performance ---\")\n\nfor model_name_cleaned in models_to_evaluate:\n    model_display_name = model_name_cleaned.replace(\"_\", \" \").title()\n    print(f\"\\nEvaluating {model_display_name}...\")\n\n    # Load predictions and probabilities from current working directory\n    y_pred = pd.read_csv(f\"y_Predictions/y_pred_{model_name_cleaned}.csv\").values.ravel()\n    y_proba = pd.read_csv(f\"y_Probabilities/y_proba_{model_name_cleaned}.csv\").values.ravel()\n\n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc_auc = roc_auc_score(y_test, y_proba)\n\n    results[model_display_name] = {\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1-Score\": f1,\n        \"ROC-AUC\": roc_auc\n    }\n\n    print(f\" Accuracy:  {accuracy:.4f}\")\n    print(f\" Precision: {precision:.4f}\")\n    print(f\" Recall:    {recall:.4f}\")\n    print(f\" F1-Score:  {f1:.4f}\")\n    print(f\" ROC-AUC:   {roc_auc:.4f}\")\n\n    # Plot Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n\n    fig, ax = plt.subplots(figsize=(6, 6))\n    disp.plot(cmap=plt.cm.Blues, ax=ax)\n    ax.set_title(f\"Confusion Matrix for {model_display_name}\")\n\n    os.makedirs(\"Confusion Matrix\", exist_ok=True)\n    plt.savefig(f\"Confusion Matrix/confusion_matrix_{model_name_cleaned}.png\")\n    plt.close(fig)  # Close the plot to free memory\n\n    print(f\" Confusion matrix saved as confusion_matrix_{model_name_cleaned}.png\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:06.277311Z","iopub.execute_input":"2025-09-20T11:49:06.277662Z","iopub.status.idle":"2025-09-20T11:49:07.173716Z","shell.execute_reply.started":"2025-09-20T11:49:06.277636Z","shell.execute_reply":"2025-09-20T11:49:07.172493Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Model Performance ---\n\nEvaluating Logistic Regression...\n Accuracy:  0.9676\n Precision: 0.9787\n Recall:    0.9553\n F1-Score:  0.9668\n ROC-AUC:   0.9940\n Confusion matrix saved as confusion_matrix_logistic_regression.png\n\nEvaluating Random Forest...\n Accuracy:  0.9973\n Precision: 0.9988\n Recall:    0.9958\n F1-Score:  0.9973\n ROC-AUC:   0.9999\n Confusion matrix saved as confusion_matrix_random_forest.png\n\nEvaluating Xgboost...\n Accuracy:  0.9988\n Precision: 0.9978\n Recall:    0.9998\n F1-Score:  0.9988\n ROC-AUC:   1.0000\n Confusion matrix saved as confusion_matrix_xgboost.png\n\nEvaluating Lightgbm...\n Accuracy:  0.9985\n Precision: 0.9980\n Recall:    0.9990\n F1-Score:  0.9985\n ROC-AUC:   0.9999\n Confusion matrix saved as confusion_matrix_lightgbm.png\n\nEvaluating Catboost...\n Accuracy:  0.9982\n Precision: 0.9972\n Recall:    0.9992\n F1-Score:  0.9982\n ROC-AUC:   0.9999\n Confusion matrix saved as confusion_matrix_catboost.png\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# Display all results in a DataFrame for easy comparison\nresults_df = pd.DataFrame(results).T\n\nprint(\"\\n--- Comprehensive Model Evaluation Results ---\")\nprint(results_df.sort_values(by=\"F1-Score\", ascending=False))\n\n# Save the comprehensive results to a CSV file in current working directory\nos.makedirs(\"Evaluation Result\", exist_ok=True)\nresults_df.to_csv(\"Evaluation Result/model_evaluation_results.csv\")\nprint(\"\\nAll model evaluation results saved to model_evaluation_results.csv\")\n\n# Optional: Plot ROC curves for all models for visual comparison\nplt.figure(figsize=(10, 8))\n\nfor model_name_cleaned in models_to_evaluate:\n    model_display_name = model_name_cleaned.replace(\"_\", \" \").title()\n    y_proba = pd.read_csv(f\"y_Probabilities/y_proba_{model_name_cleaned}.csv\").values.ravel()\n\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    plt.plot(\n        fpr, tpr,\n        label=f\"{model_display_name} (AUC = {roc_auc_score(y_test, y_proba):.2f})\"\n    )\n    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random (AUC = 0.50)\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve Comparison\")\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    \n    \n    os.makedirs(\"figures\", exist_ok=True)\n    plt.savefig(f\"figures/confusion_matrix_{model_name_cleaned}.png\")\n    plt.close()  # Close the plot to free memory\n\nprint(\"ROC curve comparison plot saved as roc_curve_comparison.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:07.174556Z","iopub.execute_input":"2025-09-20T11:49:07.174811Z","iopub.status.idle":"2025-09-20T11:49:18.215538Z","shell.execute_reply.started":"2025-09-20T11:49:07.174792Z","shell.execute_reply":"2025-09-20T11:49:18.213994Z"}},"outputs":[{"name":"stdout","text":"\n--- Comprehensive Model Evaluation Results ---\n                     Accuracy  Precision    Recall  F1-Score   ROC-AUC\nXgboost                0.9988   0.997780  0.999798  0.998788  0.999956\nLightgbm               0.9985   0.997979  0.998989  0.998484  0.999919\nCatboost               0.9982   0.997174  0.999191  0.998181  0.999928\nRandom Forest          0.9973   0.998783  0.995752  0.997265  0.999949\nLogistic Regression    0.9676   0.978657  0.955299  0.966837  0.994033\n\nAll model evaluation results saved to model_evaluation_results.csv\nROC curve comparison plot saved as roc_curve_comparison.png\n","output_type":"stream"}],"execution_count":68}]}